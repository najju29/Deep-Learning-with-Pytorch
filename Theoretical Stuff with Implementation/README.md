# Theoretical Stuff related to Deep Learning along with Implementation
1. **Activation Functions:** This notebook has mostly used Activation function's theoretical part and practical part as well.
2. **Pytorch's Training Pipeline:** It has the theoretical representation of how pytorch's pipelines are commonly built and explanation of its components.
3. **Autograd:** It has example of how to **calculating Gradients** or **Keeping track of Gradients** using **AutoGrad** module of **Pytorch.**
4. **Implementing Gradient Descent:** It has Implementation of Gradient Descent using **Numpy from Scratch** and using **Autograd's Gradient function** from *Pytorch.*
